{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is to predicct whether a bank currency note is authentic or not based on four attributes i.e.,variance of the image,wavelet transformed image,skewness,entropy and curtosis of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Set Information:\n",
    "\n",
    "Data were extracted from images that were taken from genuine and forged banknote-like specimens. For digitization, an industrial camera usually used for print inspection was used. The final images have 400x400 pixels. Due to the object lens and distance to the investigated object gray-scale pictures with a resolution of about 660 dpi were gained. Wavelet Transform tool were used to extract features from images.\n",
    "\n",
    "Attribute Information:\n",
    "1. variance of Wavelet Transformed image (continuous)\n",
    "2. skewness of Wavelet Transformed image (continuous)\n",
    "3. curtosis of Wavelet Transformed image (continuous)\n",
    "4. entropy of image (continuous)\n",
    "5. class (integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"bank_authentication.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variance</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Curtosis</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variance  Skewness  Curtosis  Entropy  Class\n",
       "0   3.62160    8.6661   -2.8073 -0.44699      0\n",
       "1   4.54590    8.1674   -2.4586 -1.46210      0\n",
       "2   3.86600   -2.6383    1.9242  0.10645      0\n",
       "3   3.45660    9.5228   -4.0112 -3.59440      0\n",
       "4   0.32924   -4.4552    4.5718 -0.98880      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variance    0\n",
       "Skewness    0\n",
       "Curtosis    0\n",
       "Entropy     0\n",
       "Class       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the dataset for training\n",
    "X = dataset.iloc[:,0:4].values\n",
    "y = dataset.iloc[:,4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the algorithm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cl = RandomForestClassifier(n_estimators=30,random_state = 1)\n",
    "cl.fit(X_train,y_train)\n",
    "y_predict = cl.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators :integer optional (default = 100)\n",
    "\n",
    "The number of trees in the forest\n",
    "\n",
    "Criterion :string,optional (default = 'gini')\n",
    "\n",
    "The function to measure the quality of the split.This parameter is tree specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[155   2]\n",
      " [  1 117]]\n",
      "0.9890909090909091\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       157\n",
      "           1       0.98      0.99      0.99       118\n",
      "\n",
      "    accuracy                           0.99       275\n",
      "   macro avg       0.99      0.99      0.99       275\n",
      "weighted avg       0.99      0.99      0.99       275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "print(confusion_matrix(y_test,y_predict))\n",
    "print(accuracy_score(y_test,y_predict))\n",
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Unfortunately there's no easy to graph the \"best\" tree or an overall ensemble tree from \n",
    "your forest,just a random example u need to consider a specific estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals.six import StringIO\n",
    "from sklearn.tree import export_graphviz\n",
    "from  pydotplus import graph_from_dot_data\n",
    "from IPython.display import Image\n",
    "dot_data = StringIO()\n",
    "export_graphviz(cl.estimators_[1],out_file=dot_data,\n",
    "                filled = True,rounded = True,\n",
    "                class_names=['0','1'])\n",
    "graph = graph_from_dot_data(dot_data.getvalue())\n",
    "Image(graph.create_png())\n",
    "graph.write_pdf('1sttree.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.predict([[3.6216,8.6661,-2.8073,-0.44699]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem here is to predict the gas consumption (in millions of gallons) in 48 of the US states based on petrol tax (in cents), per capita income (dollars), paved highways (in miles) and the proportion of population with the driving license"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv('petrol_consumption.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Petrol_tax</th>\n",
       "      <th>Average_income</th>\n",
       "      <th>Paved_Highways</th>\n",
       "      <th>Population_Driver_licence(%)</th>\n",
       "      <th>Petrol_Consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>3571</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.525</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9.00</td>\n",
       "      <td>4092</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.572</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9.00</td>\n",
       "      <td>3865</td>\n",
       "      <td>1586</td>\n",
       "      <td>0.580</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.50</td>\n",
       "      <td>4870</td>\n",
       "      <td>2351</td>\n",
       "      <td>0.529</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>8.00</td>\n",
       "      <td>4399</td>\n",
       "      <td>431</td>\n",
       "      <td>0.544</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>10.00</td>\n",
       "      <td>5342</td>\n",
       "      <td>1333</td>\n",
       "      <td>0.571</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>8.00</td>\n",
       "      <td>5319</td>\n",
       "      <td>11868</td>\n",
       "      <td>0.451</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8.00</td>\n",
       "      <td>5126</td>\n",
       "      <td>2138</td>\n",
       "      <td>0.553</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8.00</td>\n",
       "      <td>4447</td>\n",
       "      <td>8577</td>\n",
       "      <td>0.529</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>7.00</td>\n",
       "      <td>4512</td>\n",
       "      <td>8507</td>\n",
       "      <td>0.552</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>8.00</td>\n",
       "      <td>4391</td>\n",
       "      <td>5939</td>\n",
       "      <td>0.530</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>7.50</td>\n",
       "      <td>5126</td>\n",
       "      <td>14186</td>\n",
       "      <td>0.525</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>7.00</td>\n",
       "      <td>4817</td>\n",
       "      <td>6930</td>\n",
       "      <td>0.574</td>\n",
       "      <td>525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>7.00</td>\n",
       "      <td>4207</td>\n",
       "      <td>6580</td>\n",
       "      <td>0.545</td>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>7.00</td>\n",
       "      <td>4332</td>\n",
       "      <td>8159</td>\n",
       "      <td>0.608</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>7.00</td>\n",
       "      <td>4318</td>\n",
       "      <td>10340</td>\n",
       "      <td>0.586</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>7.00</td>\n",
       "      <td>4206</td>\n",
       "      <td>8508</td>\n",
       "      <td>0.572</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3718</td>\n",
       "      <td>4725</td>\n",
       "      <td>0.540</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>7.00</td>\n",
       "      <td>4716</td>\n",
       "      <td>5915</td>\n",
       "      <td>0.724</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>8.50</td>\n",
       "      <td>4341</td>\n",
       "      <td>6010</td>\n",
       "      <td>0.677</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>7.00</td>\n",
       "      <td>4593</td>\n",
       "      <td>7834</td>\n",
       "      <td>0.663</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>8.00</td>\n",
       "      <td>4983</td>\n",
       "      <td>602</td>\n",
       "      <td>0.602</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>9.00</td>\n",
       "      <td>4897</td>\n",
       "      <td>2449</td>\n",
       "      <td>0.511</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>9.00</td>\n",
       "      <td>4258</td>\n",
       "      <td>4686</td>\n",
       "      <td>0.517</td>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>8.50</td>\n",
       "      <td>4574</td>\n",
       "      <td>2619</td>\n",
       "      <td>0.551</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>9.00</td>\n",
       "      <td>3721</td>\n",
       "      <td>4746</td>\n",
       "      <td>0.544</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>8.00</td>\n",
       "      <td>3448</td>\n",
       "      <td>5399</td>\n",
       "      <td>0.548</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>7.50</td>\n",
       "      <td>3846</td>\n",
       "      <td>9061</td>\n",
       "      <td>0.579</td>\n",
       "      <td>631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>8.00</td>\n",
       "      <td>4188</td>\n",
       "      <td>5975</td>\n",
       "      <td>0.563</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>9.00</td>\n",
       "      <td>3601</td>\n",
       "      <td>4650</td>\n",
       "      <td>0.493</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3640</td>\n",
       "      <td>6905</td>\n",
       "      <td>0.518</td>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3333</td>\n",
       "      <td>6594</td>\n",
       "      <td>0.513</td>\n",
       "      <td>554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>8.00</td>\n",
       "      <td>3063</td>\n",
       "      <td>6524</td>\n",
       "      <td>0.578</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>7.50</td>\n",
       "      <td>3357</td>\n",
       "      <td>4121</td>\n",
       "      <td>0.547</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>8.00</td>\n",
       "      <td>3528</td>\n",
       "      <td>3495</td>\n",
       "      <td>0.487</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>6.58</td>\n",
       "      <td>3802</td>\n",
       "      <td>7834</td>\n",
       "      <td>0.629</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4045</td>\n",
       "      <td>17782</td>\n",
       "      <td>0.566</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3897</td>\n",
       "      <td>6385</td>\n",
       "      <td>0.586</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>8.50</td>\n",
       "      <td>3635</td>\n",
       "      <td>3274</td>\n",
       "      <td>0.663</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>7.00</td>\n",
       "      <td>4345</td>\n",
       "      <td>3905</td>\n",
       "      <td>0.672</td>\n",
       "      <td>968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>7.00</td>\n",
       "      <td>4449</td>\n",
       "      <td>4639</td>\n",
       "      <td>0.626</td>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3656</td>\n",
       "      <td>3985</td>\n",
       "      <td>0.563</td>\n",
       "      <td>699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>7.00</td>\n",
       "      <td>4300</td>\n",
       "      <td>3635</td>\n",
       "      <td>0.603</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3745</td>\n",
       "      <td>2611</td>\n",
       "      <td>0.508</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5215</td>\n",
       "      <td>2302</td>\n",
       "      <td>0.672</td>\n",
       "      <td>782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>9.00</td>\n",
       "      <td>4476</td>\n",
       "      <td>3942</td>\n",
       "      <td>0.571</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>7.00</td>\n",
       "      <td>4296</td>\n",
       "      <td>4083</td>\n",
       "      <td>0.623</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>7.00</td>\n",
       "      <td>5002</td>\n",
       "      <td>9794</td>\n",
       "      <td>0.593</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Petrol_tax  Average_income  Paved_Highways  Population_Driver_licence(%)  \\\n",
       "0         9.00            3571            1976                         0.525   \n",
       "1         9.00            4092            1250                         0.572   \n",
       "2         9.00            3865            1586                         0.580   \n",
       "3         7.50            4870            2351                         0.529   \n",
       "4         8.00            4399             431                         0.544   \n",
       "5        10.00            5342            1333                         0.571   \n",
       "6         8.00            5319           11868                         0.451   \n",
       "7         8.00            5126            2138                         0.553   \n",
       "8         8.00            4447            8577                         0.529   \n",
       "9         7.00            4512            8507                         0.552   \n",
       "10        8.00            4391            5939                         0.530   \n",
       "11        7.50            5126           14186                         0.525   \n",
       "12        7.00            4817            6930                         0.574   \n",
       "13        7.00            4207            6580                         0.545   \n",
       "14        7.00            4332            8159                         0.608   \n",
       "15        7.00            4318           10340                         0.586   \n",
       "16        7.00            4206            8508                         0.572   \n",
       "17        7.00            3718            4725                         0.540   \n",
       "18        7.00            4716            5915                         0.724   \n",
       "19        8.50            4341            6010                         0.677   \n",
       "20        7.00            4593            7834                         0.663   \n",
       "21        8.00            4983             602                         0.602   \n",
       "22        9.00            4897            2449                         0.511   \n",
       "23        9.00            4258            4686                         0.517   \n",
       "24        8.50            4574            2619                         0.551   \n",
       "25        9.00            3721            4746                         0.544   \n",
       "26        8.00            3448            5399                         0.548   \n",
       "27        7.50            3846            9061                         0.579   \n",
       "28        8.00            4188            5975                         0.563   \n",
       "29        9.00            3601            4650                         0.493   \n",
       "30        7.00            3640            6905                         0.518   \n",
       "31        7.00            3333            6594                         0.513   \n",
       "32        8.00            3063            6524                         0.578   \n",
       "33        7.50            3357            4121                         0.547   \n",
       "34        8.00            3528            3495                         0.487   \n",
       "35        6.58            3802            7834                         0.629   \n",
       "36        5.00            4045           17782                         0.566   \n",
       "37        7.00            3897            6385                         0.586   \n",
       "38        8.50            3635            3274                         0.663   \n",
       "39        7.00            4345            3905                         0.672   \n",
       "40        7.00            4449            4639                         0.626   \n",
       "41        7.00            3656            3985                         0.563   \n",
       "42        7.00            4300            3635                         0.603   \n",
       "43        7.00            3745            2611                         0.508   \n",
       "44        6.00            5215            2302                         0.672   \n",
       "45        9.00            4476            3942                         0.571   \n",
       "46        7.00            4296            4083                         0.623   \n",
       "47        7.00            5002            9794                         0.593   \n",
       "\n",
       "    Petrol_Consumption  \n",
       "0                  541  \n",
       "1                  524  \n",
       "2                  561  \n",
       "3                  414  \n",
       "4                  410  \n",
       "5                  457  \n",
       "6                  344  \n",
       "7                  467  \n",
       "8                  464  \n",
       "9                  498  \n",
       "10                 580  \n",
       "11                 471  \n",
       "12                 525  \n",
       "13                 508  \n",
       "14                 566  \n",
       "15                 635  \n",
       "16                 603  \n",
       "17                 714  \n",
       "18                 865  \n",
       "19                 640  \n",
       "20                 649  \n",
       "21                 540  \n",
       "22                 464  \n",
       "23                 547  \n",
       "24                 460  \n",
       "25                 566  \n",
       "26                 577  \n",
       "27                 631  \n",
       "28                 574  \n",
       "29                 534  \n",
       "30                 571  \n",
       "31                 554  \n",
       "32                 577  \n",
       "33                 628  \n",
       "34                 487  \n",
       "35                 644  \n",
       "36                 640  \n",
       "37                 704  \n",
       "38                 648  \n",
       "39                 968  \n",
       "40                 587  \n",
       "41                 699  \n",
       "42                 632  \n",
       "43                 591  \n",
       "44                 782  \n",
       "45                 510  \n",
       "46                 610  \n",
       "47                 524  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Petrol_tax                      0\n",
       "Average_income                  0\n",
       "Paved_Highways                  0\n",
       "Population_Driver_licence(%)    0\n",
       "Petrol_Consumption              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the dataset for training\n",
    "X = dataset.iloc[:, 0:4].values\n",
    "y = dataset.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Feature Scaling\n",
    "We know our dataset is not yet a scaled value, for instance the Average_Income field has values \n",
    "in the range of thousands while Petrol_tax has values in range of tens. \n",
    "Therefore, it would be beneficial to scale our data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the Algorithm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators=20, random_state=0)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators:integer, optional (default=10)\n",
    "\n",
    "The number of trees in the forest.\n",
    "\n",
    "criterion :string, optional (default=”mse”)\n",
    "The function to measure the quality of a split. Supported criteria are “mse” for the mean squared error, which is equal to variance reduction as feature selection criterion, and “mae” for the mean absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 51.76500000000001\n",
      "Mean Squared Error: 4216.166749999999\n",
      "Root Mean Squated Error 64.93201637097064\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "print('Mean Absolute Error:',metrics.mean_absolute_error(y_test,y_pred))\n",
    "print('Mean Squared Error:',metrics.mean_squared_error(y_test,y_pred))\n",
    "print('Root Mean Squated Error',np.sqrt(metrics.mean_squared_error(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 20 trees,the root mean squared error is 64.93 which is greate than 10% of the average of petrol consumption i.e.,576.77.This indicates that we have not used enough number of estimators(trees)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict([[9.0,3571,1976,0.525]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([506.1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the Algorithm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators=150, random_state=0)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 48.09866666666668\n",
      "Mean Squared Error: 3539.186853333334\n",
      "Root Mean Squated Error 59.49106532357052\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "print('Mean Absolute Error:',metrics.mean_absolute_error(y_test,y_pred))\n",
    "print('Mean Squared Error:',metrics.mean_squared_error(y_test,y_pred))\n",
    "print('Root Mean Squated Error',np.sqrt(metrics.mean_squared_error(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict([[7.50,4870,2351,0.529]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([505.05333333])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
